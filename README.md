# An_in-depth_exploration_of_optimization_strategies_for_Keras_pre-trained_model


## Description
This repository contains code along with two datasets that were used in research for an article titled "An in-depth exploration of optimization
for a pre-trained Keras model." 

## Authors
- Marzena Halama
- Karolina Pawlik
- Aleksandra Gres

## Affiliation
Institute of Theoretical and Applied Informatics, Polish Academy of Sciences
Silesian University of Technology, Poland

## Paper Abstract
As the complexity and scale of neural network architectures
increase, the need for efficient optimization strategies becomes paramount.
This paper presents an exhaustive exploration of optimization strategies
specifically designed for Keras pre-trained models, emphasizing the role of
transfer learning. This study introduces an innovative approach to neural
network optimization, focusing on reducing computational cost while im-
proving performance. Unlike the existing literature, our study investigates
the impact of different optimization algorithms and hyperparameter tun-
ing on network learning performance and accuracy. We show that strategic
optimization choices significantly improve model convergence speed, and
accuracy and prevent over-fitting. This research provided valuable in-
sight into the development of more efficient and accurate neural networks
dedicated to computer vision, particularly in enhancing image recognition
performance.

## Dataset Structure
The repository contains two subfolders:

- a generic database - ImageNette - approximately 1300 images per class
- a custom database - ToyVision - 300 per class


## Usage
The repository contains scripts for each model separately containing the full implementation giving the ability to reproduce the research.

